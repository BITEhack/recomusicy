{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b1a614",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5118c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Piotr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Piotr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from itertools import product\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18415a62",
   "metadata": {},
   "source": [
    "# **Exploring data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d0775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training.csv\") # header = None names=[\"idk\", \"id\", \"date\", \"query\", \"nick\", \"content\"])\n",
    "# data.drop([\"idk\", \"query\", \"nick\"], axis=1, inplace=True)\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a08f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ffed1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  object\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e00ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "15995  i just had a very brief time in the beanbag an...      0\n",
       "15996  i am now turning and i feel pathetic that i am...      0\n",
       "15997                     i feel strong and good overall      1\n",
       "15998  i feel like this was such a rude comment and i...      3\n",
       "15999  i know a lot but i feel so stupid because i ca...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a80b71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16000 entries, 0 to 15999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    16000 non-null  object\n",
      " 1   label   16000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32a175",
   "metadata": {},
   "source": [
    "# **Cleaning data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ce4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "custom_stopwords = [\"http\", \"https\", \"www\", \"com\", \"tinyurl\"]\n",
    "\n",
    "# credit to https://pytutorial.com/check-strig-url\n",
    "url_pattern = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119f0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_verify(line, custom_stopwords, url_pattern, lemmatizer):\n",
    "    line = line.lower()\n",
    "    line = remove_stopwords(line)\n",
    "    res = []\n",
    "    for word in str(line).split(' '):\n",
    "        if url_pattern.match(word) is None:\n",
    "            res.append(word)\n",
    "            \n",
    "    res = [lemmatizer.lemmatize(re.sub(\"[^a-zA-Z@' $]\", \" \", word)) for word in res]\n",
    "    \n",
    "    temp = []\n",
    "    for word in res:\n",
    "        for part in word.split(' '):\n",
    "            part = lemmatizer.lemmatize(re.sub(\"[^a-zA-Z$]\", \"\", part))\n",
    "            # eliminate nicknames and words that are empty/of length 1\n",
    "            if len(part) > 1 and word[0] != '@' and ' ' not in part and part not in custom_stopwords:\n",
    "                temp.append(part)\n",
    "    \n",
    "    res = (' ').join(temp)\n",
    "    res = remove_stopwords(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95263f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xdata = np.asarray([process_and_verify(line, custom_stopwords, url_pattern, lemmatizer) for line in data['text']])\n",
    "\n",
    "X_final_test = np.asarray([process_and_verify(line, custom_stopwords, url_pattern, lemmatizer) for line in test_data['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829be15",
   "metadata": {},
   "source": [
    "# **Encoding data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f98f3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "Xdata_encoded = np.asarray(vectorizer.fit_transform(Xdata).todense())\n",
    "X_final_test_encoded = np.asarray(vectorizer.transform(X_final_test).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a443b6",
   "metadata": {},
   "source": [
    "# **Searching for optimal hiperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86b4ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample training just to see if everything works fine - accuracy around 85%\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xdata_encoded, data['label'], test_size=0.20)\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_res = classifier.predict(X_test)\n",
    "precision_recall_fscore_support(y_test, y_res)\n",
    "\n",
    "accuracy_score(y_test, y_res)\n",
    "\n",
    "# cross_val_score(classifier, Xdata_encoded, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7bc1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for cartesian product of the dict - actually redudant in the code below\n",
    "def params_product(params):\n",
    "    return (dict(zip(params.keys(), values)) for values in product(*params.values()))\n",
    "\n",
    "# for logistic regression\n",
    "def custom_grid_search(X, y, params):\n",
    "    X, y = shuffle(X, y)\n",
    "    best_score = 0\n",
    "    best_kwargs = dict()\n",
    "    for kwargs in params_product(params):\n",
    "        print(kwargs)\n",
    "        classifier = LogisticRegression(**kwargs, solver='liblinear')\n",
    "        score = sum(cross_val_score(classifier, X, y)) / 5\n",
    "        print(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_kwargs = kwargs\n",
    "    return best_kwargs\n",
    "\n",
    "# has result only if key 'C' is in hiperparams\n",
    "def adjust_regularization_parameter(X, y, hiperparams):\n",
    "    if 'C' in hiperparams:\n",
    "        best_score = 0\n",
    "        best_c = 0\n",
    "        \n",
    "        for x in range(10*(hiperparams['C'] - 1), 10*(hiperparams['C'] + 1) + 1, 1):\n",
    "            c = x / 10\n",
    "            classifier = LogisticRegression(C=c, solver='liblinear')\n",
    "            print(c)\n",
    "            score = sum(cross_val_score(classifier, X, y)) / 5\n",
    "            print(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_c = c\n",
    "            \n",
    "    return best_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7766f1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.8500624999999999\n",
      "{'C': 2}\n",
      "0.8703125\n",
      "{'C': 3}\n",
      "0.8761875\n",
      "{'C': 4}\n",
      "0.8778750000000001\n",
      "{'C': 5}\n",
      "0.8791874999999999\n",
      "{'C': 6}\n",
      "0.8805624999999999\n",
      "{'C': 7}\n",
      "0.880875\n",
      "{'C': 8}\n",
      "0.8811250000000002\n",
      "{'C': 9}\n",
      "0.8815\n",
      "{'C': 10}\n",
      "0.8815000000000002\n",
      "{'C': 11}\n",
      "0.882\n",
      "{'C': 12}\n",
      "0.8824375\n",
      "{'C': 13}\n",
      "0.8829374999999999\n"
     ]
    }
   ],
   "source": [
    "# looking for optimal regularization factor (the higher, the less complex the model)\n",
    "params = {\"C\": [x for x in range(1, 14)]}\n",
    "hiperparams = custom_grid_search(Xdata_encoded, data['label'], params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3956a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "0.8790625000000001\n",
      "12.1\n",
      "0.8790000000000001\n",
      "12.2\n",
      "0.8787500000000001\n",
      "12.3\n",
      "0.8786875000000001\n",
      "12.4\n",
      "0.8787499999999999\n",
      "12.5\n",
      "0.8787499999999999\n",
      "12.6\n",
      "0.8786875000000001\n",
      "12.7\n",
      "0.8786875000000001\n",
      "12.8\n",
      "0.8787499999999999\n",
      "12.9\n",
      "0.8786875000000001\n",
      "13.0\n",
      "0.8786250000000001\n",
      "13.1\n",
      "0.8785000000000001\n",
      "13.2\n",
      "0.8785000000000001\n",
      "13.3\n",
      "0.8784374999999999\n",
      "13.4\n",
      "0.8784374999999999\n",
      "13.5\n",
      "0.8783749999999999\n",
      "13.6\n",
      "0.8783749999999999\n",
      "13.7\n",
      "0.8783124999999998\n",
      "13.8\n",
      "0.8782499999999999\n",
      "13.9\n",
      "0.8782499999999999\n",
      "14.0\n",
      "0.8782500000000001\n"
     ]
    }
   ],
   "source": [
    "hiperparams['C'] = adjust_regularization_parameter(Xdata_encoded, data['label'], hiperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4644ccc",
   "metadata": {},
   "source": [
    "# **Training and testing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9720b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=12.0, solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = LogisticRegression(**hiperparams, solver='liblinear')\n",
    "final_model.fit(Xdata_encoded, data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd3552d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.91808874, 0.89958159, 0.78571429, 0.875     , 0.86175115,\n",
       "        0.81481481]),\n",
       " array([0.92598967, 0.92805755, 0.76100629, 0.86545455, 0.83482143,\n",
       "        0.66666667]),\n",
       " array([0.92202228, 0.91359773, 0.77316294, 0.8702011 , 0.84807256,\n",
       "        0.73333333]),\n",
       " array([581, 695, 159, 275, 224,  66], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = final_model.predict(X_final_test_encoded)\n",
    "\n",
    "precision_recall_fscore_support(test_data['label'], y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a50b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8865"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_data['label'], y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ec49b6",
   "metadata": {},
   "source": [
    "# **Saving model to file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdff074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelTextEmotions.sav']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final_model, \"ModelTextEmotions.sav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
